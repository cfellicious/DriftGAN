{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50efdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import process_data\n",
    "from utils import read_dataset\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e47720",
   "metadata": {},
   "source": [
    "### Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb891db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all parameters for the experiment\n",
    "# Maximum dataset size to be considered as keeping track of previous drifts slows the system down considerably\n",
    "# Default: 50000\n",
    "max_dataset_size = 50000 \n",
    "# Training window size. Default: 100\n",
    "training_window_size = 100\n",
    "# Training epochs. Default: 150\n",
    "epochs = 150\n",
    "# Set repeat factor. 1/factor will be the number of instances from previous instances that are considered for training\n",
    "# Default: 25. This means 4% data from previous identical drift windows will be added to the current training data\n",
    "repeat_factor = 25\n",
    "# Equalize the number of training instances across different drifts. Default: True\n",
    "equalize = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20429525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN parameters\n",
    "\n",
    "# Sequence length for the generator. Default: 10\n",
    "sequence_length = 10\n",
    "\n",
    "# For the collate function to split the rows accordingly\n",
    "seq_len = sequence_length\n",
    "\n",
    "# Training steps. default: 100\n",
    "steps_generator = 100\n",
    "\n",
    "# Set the batch_size of the discriminator. Default: 8\n",
    "batch_size = 8\n",
    "\n",
    "# Batch size for training the generator\n",
    "generator_batch_size = 8\n",
    "\n",
    "# Number of instances that should have the same label for a drift to be confirmed. Default: 4\n",
    "test_batch_size = 4\n",
    "\n",
    "# Set the learning rate. Default: 0.001\n",
    "lr = 0.001  \n",
    "\n",
    "# Set the weight decay rate. Default: 0.00005\n",
    "weight_decay = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a220ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seeds to get some deterministic behaviour in the experiment\n",
    "seed = np.random.randint(65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e772905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training to cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dac649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the dataset name for loading the data.\n",
    "# The datafiles can be obtained from https://github.com/ogozuacik/concept-drift-datasets-scikit-multiflow\n",
    "# Dataset names: airlines, chess, covtrype, electricity, ludata, outdoor, phishing, poker, rialto, spam\n",
    "dataset_name = 'outdoor'\n",
    "features, labels = read_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0277bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset exceeds the maximum dataset size, clip the dataset\n",
    "features = features[:max_dataset_size]\n",
    "labels = labels[:max_dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c515d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset for the GAN\n",
    "features = np.array(features)\n",
    "mean = np.mean(features, axis=1).reshape(features.shape[0], 1)\n",
    "std = np.std(features, axis=1).reshape(features.shape[0], 1)\n",
    "\n",
    "standardized_features = (features - mean)/(std + 0.000001)\n",
    "concatenated_features = features \n",
    "features = (features - mean)/(std + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10650a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "220\n",
      "320\n",
      "420\n",
      "520\n",
      "620\n",
      "720\n",
      "820\n",
      "920\n",
      "1020\n",
      "1124\n",
      "1224\n",
      "1324\n",
      "1424\n",
      "1532\n",
      "1632\n",
      "1732\n",
      "1832\n",
      "1932\n",
      "2032\n",
      "2132\n",
      "2232\n",
      "2332\n",
      "2440\n",
      "2540\n",
      "2640\n",
      "2740\n",
      "2852\n",
      "2952\n",
      "3052\n",
      "3156\n",
      "3256\n",
      "3356\n",
      "3456\n",
      "3556\n",
      "3656\n",
      "3756\n",
      "3856\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "y_pred, y_true, drifts_detected = process_data(features=features, labels=labels, device=device, epochs=epochs,\n",
    "                                               steps_generator=steps_generator, seed=seed,\n",
    "                                               batch_size=batch_size, lr=lr,\n",
    "                                               weight_decay=weight_decay, test_batch_size=test_batch_size,\n",
    "                                               training_window_size=training_window_size,\n",
    "                                               generator_batch_size=generator_batch_size, equalize=equalize,\n",
    "                                               sequence_length=sequence_length, repeat_factor=repeat_factor,\n",
    "                                               training_features=concatenated_features)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2bc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time is 14726 seconds\n"
     ]
    }
   ],
   "source": [
    "# print the time taken to execute\n",
    "exec_time = t2 - t1\n",
    "print('Execution time is %d seconds' % exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2004dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy value is 0.589750 for dataset outdoor\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_value = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "print(' Accuracy value is %f for dataset %s' % (accuracy_value, dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d047e876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of drifts is 38\n"
     ]
    }
   ],
   "source": [
    "# print the number of detected drifts\n",
    "print('No. of drifts is %d' % len(drifts_detected))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:student_env] *",
   "language": "python",
   "name": "conda-env-student_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
